{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f896245e-57c4-48fd-854f-9e43f22e10c9",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7fc8a0-280c-4979-b0c7-fc3a99b3b785",
   "metadata": {},
   "source": [
    "# Appendix A: Introduction to PyTorch (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bf13d2-8fc2-483e-88cc-6b4310221e68",
   "metadata": {},
   "source": [
    "## A.1 What is PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ee5660-5327-48e2-9104-a882b3b2afa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73ad4e4-7ec6-4467-a9e9-0cdf6d195264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397ba1ab-3306-4965-8618-1ed5f24fb939",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/1.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c0555-88f6-4515-8c99-aa56b0769d54",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/2.webp\" width=\"300px\">\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/3.webp\" width=\"300px\">\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/4.webp\" width=\"500px\">\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/5.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2100cf2e-7459-4ab3-92a8-43e86ab35a9b",
   "metadata": {},
   "source": [
    "## A.2 Understanding tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c484e87-bfc9-4105-b0a7-1e23b2a72a30",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/6.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d7f785-e048-42bc-9182-a556af6bb7f4",
   "metadata": {},
   "source": [
    "### A.2.1 Scalars, vectors, matrices, and tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3a464d6-cec8-4363-87bd-ea4f900baced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52cae21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create a 0D tensor (scalar) from a Python integer\n",
    "tensor0d = torch.tensor(1)\n",
    "tensor0d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c366c893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create a 1D tensor (vector) from a Python list\n",
    "tensor1d = torch.tensor([1, 2, 3])\n",
    "\n",
    "# create a 2D tensor from a nested Python list\n",
    "tensor2d = torch.tensor([[1, 2], \n",
    "                         [3, 4]])\n",
    "\n",
    "tensor2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a76dc469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a 3D tensor from a nested Python list\n",
    "tensor3d_1 = torch.tensor([[[1, 2], [3, 4]], \n",
    "                           [[5, 6], [7, 8]]])\n",
    "\n",
    "# create a 3D tensor from NumPy array\n",
    "ary3d = np.array([[[1, 2], [3, 4]], \n",
    "                  [[5, 6], [7, 8]]])\n",
    "tensor3d_2 = torch.tensor(ary3d)  # Copies NumPy array\n",
    "tensor3d_3 = torch.from_numpy(ary3d)  # Shares memory with NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "986a258c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[5, 6],\n",
       "         [7, 8]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbe14c47-499a-4d48-b354-a0e6fd957872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "ary3d[0, 0, 0] = 999\n",
    "print(tensor3d_2) # remains unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3e4c23a-cdba-46f5-a2dc-5fb32bf9117b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[999,   2],\n",
      "         [  3,   4]],\n",
      "\n",
      "        [[  5,   6],\n",
      "         [  7,   8]]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor3d_3) # changes because of memory sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dec48d-2b60-41a2-ac06-fef7e718605a",
   "metadata": {},
   "source": [
    "### A.2.2 Tensor data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f48c014-e1a2-4a53-b5c5-125812d4034c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "tensor1d = torch.tensor([1, 2, 3])\n",
    "print(tensor1d.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5429a086-9de2-4ac7-9f14-d087a7507394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "floatvec = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(floatvec.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9a438d1-49bb-481c-8442-7cc2bb3dd4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "floatvec = tensor1d.to(torch.float32)\n",
    "print(floatvec.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2020deb5-aa02-4524-b311-c010f4ad27ff",
   "metadata": {},
   "source": [
    "### A.2.3 Common PyTorch tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c02095f2-8a48-4953-b3c9-5313d4362ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d = torch.tensor([[1, 2, 3], \n",
    "                         [4, 5, 6]])\n",
    "tensor2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f33e1d45-5b2c-4afe-b4b2-66ac4099fd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3a4129d-f870-4e03-9c32-cd8521cb83fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d.reshape(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "589ac0a7-adc7-41f3-b721-155f580e9369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d.view(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "344e307f-ba5d-4f9a-a791-2c75a3d1417e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19a75030-6a41-4ca8-9aae-c507ae79225c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 32],\n",
       "        [32, 77]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d.matmul(tensor2d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7c950bc-d640-4203-b210-3ac8932fe4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 32],\n",
       "        [32, 77]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d @ tensor2d.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15bdeb-78e2-4870-8a4f-a9f591666f38",
   "metadata": {},
   "source": [
    "## A.3 Seeing models as computation graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3e16c3-07df-44b6-9106-a42fb24452a9",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/7.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22af61e9-0443-4705-94d7-24c21add09c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfb9d87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0852)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = torch.tensor([1.0])  # true label\n",
    "x1 = torch.tensor([1.1]) # input feature\n",
    "w1 = torch.tensor([2.2]) # weight parameter\n",
    "b = torch.tensor([0.0])  # bias unit\n",
    "\n",
    "z = x1 * w1 + b          # net input\n",
    "a = torch.sigmoid(z)     # activation & output\n",
    "\n",
    "loss = F.binary_cross_entropy(a, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9424f26-2bac-47e7-b834-92ece802247c",
   "metadata": {},
   "source": [
    "## A.4 Automatic differentiation made easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aa2ee4-6f1d-448d-8707-67cd5278233c",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/8.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebf5cef7-48d6-4d2a-8ab0-0fb10bdd7d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0852, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "\n",
    "y = torch.tensor([1.0])\n",
    "x1 = torch.tensor([1.1])\n",
    "w1 = torch.tensor([2.2], requires_grad=True)\n",
    "b = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "z = x1 * w1 + b \n",
    "a = torch.sigmoid(z)\n",
    "\n",
    "loss = F.binary_cross_entropy(a, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0211d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.0898]),)\n",
      "(tensor([-0.0817]),)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grad_L_w1 = grad(loss, w1, retain_graph=True)\n",
    "grad_L_b = grad(loss, b, retain_graph=True)\n",
    "\n",
    "print(grad_L_w1)\n",
    "print(grad_L_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93c5875d-f6b2-492c-b5ef-7e132f93a4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0898])\n",
      "tensor([-0.0817])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "\n",
    "print(w1.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53bdd7d-44e6-40ab-8a5a-4eef74ef35dc",
   "metadata": {},
   "source": [
    "## A.5 Implementing multilayer neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb9787-2bc8-4379-9e8c-a3401ac63c51",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/9.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84b749e1-7768-4cfe-94d6-a08c7feff4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "                \n",
    "            # 1st hidden layer\n",
    "            torch.nn.Linear(num_inputs, 30),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # 2nd hidden layer\n",
    "            torch.nn.Linear(30, 20),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # output layer\n",
    "            torch.nn.Linear(20, num_outputs),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5b59e2e-1930-456d-93b9-f69263e3adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39d02a21-33e7-4879-8fd2-d6309faf2f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94535738-de02-4c2a-9b44-1cd186fa990a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable model parameters: 2213\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of trainable model parameters:\", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5694515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0463,  0.0578, -0.0187,  ...,  0.0253, -0.0897, -0.0720],\n",
       "         [-0.0073, -0.0484, -0.0089,  ..., -0.0108, -0.0800,  0.0053],\n",
       "         [ 0.0588,  0.0185,  0.1333,  ..., -0.1278, -0.0539, -0.0120],\n",
       "         ...,\n",
       "         [-0.0479, -0.1268, -0.0777,  ..., -0.0281, -0.0116,  0.0285],\n",
       "         [-0.0121, -0.0867, -0.0006,  ..., -0.1192, -0.0901, -0.0367],\n",
       "         [ 0.1091,  0.0244, -0.1025,  ...,  0.0948,  0.0506, -0.0906]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1135,  0.0713, -0.0604, -0.0176,  0.0874,  0.0615,  0.0673,  0.1201,\n",
       "         -0.1013, -0.0457,  0.0761, -0.1314,  0.0165,  0.0938, -0.0972, -0.0570,\n",
       "         -0.0299, -0.1398,  0.1234, -0.1051, -0.0601, -0.1201, -0.0365, -0.1312,\n",
       "         -0.0982, -0.1209,  0.0733, -0.1275, -0.1207, -0.0442],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-9.0470e-02, -9.4410e-02, -4.5558e-02, -5.3091e-02, -9.7569e-03,\n",
       "          -8.7195e-02, -1.2091e-03,  5.6578e-02,  2.5693e-02, -9.0662e-02,\n",
       "          -5.9525e-02, -1.1393e-01,  1.4036e-02, -9.9116e-02, -4.6424e-02,\n",
       "          -8.9875e-02,  1.0235e-01,  4.9684e-02,  1.2679e-01,  9.4812e-03,\n",
       "          -3.8431e-02,  8.4427e-02, -1.5810e-01,  1.4102e-01,  1.4513e-01,\n",
       "          -1.1219e-01, -1.1252e-01, -7.4968e-02, -4.4939e-03,  7.8575e-02],\n",
       "         [ 6.4999e-03, -1.4309e-01,  9.4231e-02,  1.6988e-01,  1.6782e-01,\n",
       "          -1.6328e-01, -8.9261e-04, -1.4881e-01,  8.0247e-02, -3.1162e-02,\n",
       "          -1.6844e-01, -1.5832e-01, -8.7144e-02,  1.8962e-02, -1.2749e-01,\n",
       "           6.3994e-02, -1.2388e-01,  8.0932e-02, -1.4446e-01,  9.4866e-02,\n",
       "          -2.1161e-02, -2.0103e-02,  2.2989e-02,  3.9571e-02, -1.2698e-01,\n",
       "           1.3198e-01,  1.5783e-01, -2.7152e-02, -1.6281e-01,  1.6392e-01],\n",
       "         [ 9.1682e-02, -1.0274e-01, -1.7797e-01,  4.9079e-02,  4.7392e-02,\n",
       "          -1.4525e-01,  1.4611e-01, -1.1388e-01, -1.0210e-01, -3.3347e-02,\n",
       "           4.4458e-02,  1.1691e-01, -9.0398e-02, -6.8120e-02,  1.6824e-01,\n",
       "          -1.6849e-01, -8.9195e-02, -1.0262e-01, -2.4831e-03, -1.6356e-01,\n",
       "          -2.8734e-02,  5.7627e-02, -5.0323e-02,  1.6486e-01,  1.3327e-02,\n",
       "          -4.5596e-02, -1.5506e-01, -1.3032e-01,  2.6619e-03,  7.0073e-02],\n",
       "         [ 3.1929e-02, -3.4089e-02, -6.4691e-03,  9.7142e-02,  1.6519e-01,\n",
       "          -1.4882e-01,  4.8782e-02,  6.1919e-02, -8.2072e-02,  1.6766e-01,\n",
       "          -7.6954e-02, -4.4730e-04,  7.1569e-02, -1.3721e-02,  1.4263e-01,\n",
       "          -1.7583e-01,  7.7669e-02,  7.1482e-02, -1.4001e-01,  1.1092e-01,\n",
       "           7.1357e-02, -3.1236e-02,  7.6514e-02,  3.3595e-02, -1.4231e-01,\n",
       "          -1.8435e-02, -7.1298e-02, -1.6075e-01, -5.1345e-03,  3.9430e-02],\n",
       "         [ 1.1995e-01, -8.6032e-02,  1.7854e-01,  5.7322e-03, -1.2722e-01,\n",
       "          -1.6179e-02,  1.1393e-01, -9.0925e-02, -1.0361e-02, -1.0622e-01,\n",
       "           4.0941e-02, -2.9991e-02,  1.0283e-01,  4.9302e-02, -6.8143e-02,\n",
       "          -9.4983e-04,  6.0284e-02, -1.2249e-01,  1.0772e-01,  6.0110e-02,\n",
       "           9.2304e-02, -6.1546e-02, -8.4191e-02, -1.5243e-01, -1.4734e-01,\n",
       "          -6.6143e-02,  8.1841e-02, -1.0868e-01, -1.3566e-01, -1.6722e-01],\n",
       "         [-1.7425e-01,  6.2041e-02,  1.8211e-01,  4.4871e-02,  1.1043e-01,\n",
       "          -4.1050e-02, -2.9490e-02, -3.6706e-02,  5.4728e-02, -1.5778e-01,\n",
       "          -1.3359e-01,  1.6427e-01, -1.2949e-01, -1.2331e-01, -2.6869e-02,\n",
       "           1.2669e-01, -8.5002e-02,  9.6059e-02,  1.7685e-01,  1.9415e-03,\n",
       "           1.1868e-01,  5.6305e-02,  1.4421e-01,  2.1639e-02,  1.2735e-01,\n",
       "           1.2664e-01, -7.4254e-02,  7.1373e-02, -1.1699e-01,  7.9774e-02],\n",
       "         [-1.7240e-01,  1.0927e-01, -5.1310e-02,  6.8380e-02, -1.8017e-01,\n",
       "          -7.4459e-04, -1.0984e-01,  1.1914e-01,  1.6718e-01, -6.0467e-02,\n",
       "          -3.4556e-02,  1.3319e-01,  1.1955e-01,  3.5937e-02, -1.3044e-01,\n",
       "          -9.0812e-02,  9.9440e-02,  1.3173e-01, -1.4643e-01, -9.3015e-02,\n",
       "           1.7501e-01, -4.9027e-02,  5.9996e-02, -1.3263e-01,  6.0312e-02,\n",
       "           6.7053e-02,  1.6597e-01, -6.2594e-02, -1.7165e-01,  7.7840e-02],\n",
       "         [ 1.1462e-01,  3.0397e-02,  1.5186e-01,  1.5624e-01,  1.8156e-01,\n",
       "          -1.4099e-01, -2.3982e-02, -5.9161e-02, -7.9993e-02,  7.4704e-02,\n",
       "          -7.6193e-02,  1.5916e-01,  1.7012e-01, -1.8113e-01,  3.4735e-02,\n",
       "           7.5263e-02,  1.1818e-01, -1.2486e-01,  1.4437e-01,  8.5860e-02,\n",
       "           2.6878e-02,  1.6732e-01,  1.1233e-01, -1.6217e-01, -6.1815e-02,\n",
       "          -1.5481e-01,  1.8140e-01, -2.7741e-02,  1.3692e-01, -9.3553e-02],\n",
       "         [-2.1887e-02, -4.8728e-02, -3.8219e-02, -1.3810e-01, -1.7407e-01,\n",
       "           8.5830e-02,  1.6519e-01,  4.0382e-03, -6.4226e-02, -1.8089e-01,\n",
       "           4.1591e-02,  1.5698e-01,  1.6220e-01,  1.2770e-01, -1.7911e-01,\n",
       "          -9.7022e-02, -6.5379e-02, -1.4674e-01,  6.5608e-02,  1.0884e-01,\n",
       "          -1.1492e-02,  6.5500e-02, -5.9069e-02,  1.1158e-01,  4.4838e-02,\n",
       "          -1.7903e-01, -5.7037e-02, -3.0939e-02,  2.6257e-02,  1.0402e-01],\n",
       "         [-8.3858e-02, -7.0723e-02,  1.6871e-01,  8.3424e-02,  2.5027e-02,\n",
       "          -8.3062e-02,  5.3329e-02, -1.4632e-01,  8.2591e-02, -6.3624e-02,\n",
       "          -9.2099e-02, -1.7526e-01, -1.0343e-01,  8.8580e-02,  1.3023e-01,\n",
       "          -1.7763e-01,  1.2826e-01,  3.9519e-02,  1.3342e-01, -1.3083e-01,\n",
       "           1.7684e-01,  1.7289e-02,  8.5610e-02, -1.1236e-01, -9.7320e-03,\n",
       "           4.9238e-02,  1.7947e-01,  7.5294e-02, -9.3813e-02,  1.0018e-01],\n",
       "         [-1.0910e-01,  1.5666e-01,  1.5164e-01, -1.3113e-01,  3.6641e-03,\n",
       "          -8.0826e-02, -9.2072e-02,  2.5199e-02,  1.8486e-02, -1.6405e-01,\n",
       "           1.8457e-02, -7.1972e-02,  3.1582e-03,  1.1211e-02, -6.1084e-02,\n",
       "           1.4734e-02,  1.5217e-01,  9.6692e-02,  1.5116e-01,  1.8376e-02,\n",
       "          -3.6211e-02,  1.7388e-02, -5.8501e-02, -8.6673e-02, -1.2626e-01,\n",
       "           1.5247e-01, -1.3674e-01, -6.1547e-02, -1.0449e-01, -1.7603e-01],\n",
       "         [ 5.4002e-03,  7.8175e-02,  1.7457e-01, -7.8138e-02, -9.4932e-02,\n",
       "          -1.7449e-01,  1.5766e-01,  1.2560e-01, -4.1512e-02, -6.7451e-02,\n",
       "          -2.5061e-02,  1.6259e-01,  1.3339e-01,  5.1004e-02,  1.0787e-01,\n",
       "           6.7981e-02, -1.6694e-01,  9.7258e-02,  7.9882e-02, -6.6119e-02,\n",
       "          -1.4662e-01, -1.4068e-02,  5.1156e-02,  5.4192e-02,  1.2413e-01,\n",
       "           1.2526e-01,  4.7473e-02,  1.6814e-01, -1.2065e-01,  1.6444e-01],\n",
       "         [-5.8858e-02,  6.1398e-02,  7.9014e-02, -1.4098e-01,  1.1159e-04,\n",
       "           1.0153e-03,  1.3700e-01,  2.8785e-02, -5.9108e-02,  1.1221e-01,\n",
       "          -1.2447e-01, -2.8597e-02, -1.8313e-02,  1.1875e-01, -6.1233e-02,\n",
       "           1.0578e-01,  1.9009e-02,  6.8851e-02, -6.7717e-02,  1.5880e-01,\n",
       "          -1.4276e-01,  9.7319e-02, -1.6048e-01, -7.1184e-02,  6.9817e-03,\n",
       "           8.9702e-02,  1.5728e-01, -1.0698e-01, -1.5522e-01, -5.1202e-02],\n",
       "         [ 1.5760e-01,  1.0443e-02,  7.6900e-02, -1.3564e-01, -1.6364e-01,\n",
       "           1.1153e-01, -1.8108e-01,  1.8298e-02,  5.3911e-02,  1.2283e-01,\n",
       "           4.1169e-02,  6.6442e-02, -5.5409e-02, -6.6901e-02,  2.9874e-02,\n",
       "          -1.0100e-01,  5.9278e-02,  1.5805e-01,  1.3861e-01, -1.0521e-01,\n",
       "           1.0207e-01, -1.5246e-01, -9.5965e-03,  1.4482e-01, -6.8871e-02,\n",
       "          -8.7981e-02,  1.4418e-01,  1.1322e-01, -2.1581e-02,  5.1480e-02],\n",
       "         [ 3.7404e-03,  7.6513e-02, -1.5257e-01,  1.2404e-01, -1.6372e-01,\n",
       "          -1.1777e-01,  7.0368e-02, -5.5572e-02, -1.9506e-02, -5.8415e-02,\n",
       "          -1.0594e-01, -9.6007e-02,  9.7833e-02,  7.6594e-03,  8.7893e-02,\n",
       "          -1.7389e-01,  3.0862e-03,  8.6834e-03, -2.6730e-02,  1.6647e-01,\n",
       "          -1.7893e-01, -1.7399e-01, -4.7755e-02,  1.4466e-02,  5.2296e-02,\n",
       "           2.2313e-02,  3.5333e-02, -1.3735e-01, -1.5194e-01, -1.5942e-02],\n",
       "         [-1.3589e-01,  1.6319e-01,  7.4482e-02, -9.1400e-03, -1.7050e-01,\n",
       "           5.7126e-02, -1.6199e-01,  1.6993e-01, -1.7670e-01, -1.4022e-01,\n",
       "           4.5947e-02,  1.1781e-01, -1.7183e-01,  3.0320e-02,  1.7494e-01,\n",
       "           9.1825e-02, -8.1748e-04, -1.6721e-01,  1.2838e-01, -1.8066e-01,\n",
       "           1.6798e-01,  9.7165e-03, -1.7807e-01, -1.5436e-01, -1.3445e-01,\n",
       "          -7.8752e-02, -7.9457e-02,  1.4972e-01,  1.1805e-01,  6.2574e-02],\n",
       "         [ 1.4516e-01, -1.5010e-01,  7.9415e-02,  9.6044e-02,  1.2046e-01,\n",
       "           1.8212e-01,  1.1403e-01,  1.8038e-01, -2.3062e-02,  1.1516e-01,\n",
       "           1.9184e-03, -1.3698e-01,  1.4552e-01, -1.5932e-01, -1.1687e-01,\n",
       "          -1.1367e-01, -3.5256e-02, -2.0424e-02, -1.7048e-01, -9.3264e-02,\n",
       "           1.9157e-02,  1.3182e-01, -1.6788e-01,  7.1688e-02, -1.4346e-01,\n",
       "          -9.5479e-04,  5.3115e-02, -1.1667e-01,  1.5362e-01, -1.5674e-01],\n",
       "         [-6.4991e-03, -1.0641e-01,  5.1005e-02,  1.1230e-01,  1.1333e-01,\n",
       "           6.2602e-02, -3.4863e-03,  1.6059e-01,  8.1094e-02,  6.3024e-02,\n",
       "           8.6017e-02,  9.7994e-02,  1.6569e-01, -3.1205e-02,  1.0129e-01,\n",
       "           1.2242e-01,  1.2517e-01,  1.4697e-02, -5.2028e-02,  1.2697e-01,\n",
       "           1.3318e-02, -1.4245e-01,  9.3354e-02,  1.1547e-01, -1.7005e-02,\n",
       "          -2.2059e-02,  6.7899e-02, -2.1050e-02, -5.3902e-02, -8.7929e-02],\n",
       "         [ 7.2385e-02,  8.2375e-02, -1.2931e-01, -5.2135e-02,  6.5156e-02,\n",
       "          -1.2696e-01, -5.7035e-02, -8.4768e-02, -1.4225e-01, -7.8606e-02,\n",
       "          -1.6601e-01, -1.2894e-01,  1.1910e-01, -1.7488e-01, -1.1895e-01,\n",
       "          -1.2739e-01, -8.2535e-02,  1.8202e-01, -5.7987e-02,  9.3484e-02,\n",
       "          -4.2344e-02,  1.6461e-01, -1.9895e-02, -1.3003e-01, -1.3370e-01,\n",
       "           1.3304e-01,  1.5297e-01,  1.8257e-01, -1.4817e-01, -2.9454e-03],\n",
       "         [ 1.4529e-01,  2.7329e-02,  8.1827e-02, -3.3869e-02, -1.3211e-01,\n",
       "           1.3911e-01, -1.7599e-01,  1.0889e-01, -7.2338e-02,  8.5704e-02,\n",
       "          -1.5329e-01,  1.1969e-01, -1.3601e-01, -5.8137e-02, -7.8017e-02,\n",
       "          -1.2841e-01, -6.5676e-02, -3.2898e-02, -3.4060e-02, -1.0240e-01,\n",
       "          -1.3046e-01,  1.5630e-02,  6.7569e-02, -2.3300e-02,  6.2373e-02,\n",
       "          -8.3973e-02,  6.2471e-02, -1.5686e-01,  3.4872e-02, -1.6254e-01]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0600, -0.1751, -0.1376, -0.1006, -0.1060, -0.0999, -0.1114, -0.0727,\n",
       "         -0.0273, -0.1358,  0.0738,  0.0503,  0.1572,  0.0437, -0.0547, -0.1326,\n",
       "          0.0299,  0.0364, -0.1490, -0.0910], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0883, -0.0164, -0.0214,  0.0956, -0.0961, -0.0761, -0.0225, -0.0146,\n",
       "          -0.1288,  0.1898,  0.1993, -0.0645, -0.0699,  0.2080, -0.1700,  0.0578,\n",
       "          -0.1888, -0.0466, -0.0524, -0.1934],\n",
       "         [ 0.1288,  0.1006, -0.1514, -0.1116,  0.1606, -0.1835,  0.0597, -0.0706,\n",
       "          -0.0882, -0.1969, -0.1736,  0.0697, -0.1481, -0.1152, -0.0369, -0.1907,\n",
       "           0.1499,  0.2110, -0.0444,  0.0093],\n",
       "         [-0.1858, -0.0807,  0.0733,  0.1024, -0.0108,  0.1812, -0.1192, -0.1615,\n",
       "           0.1905,  0.1070, -0.0374, -0.1620,  0.1785, -0.0232, -0.1257, -0.0793,\n",
       "          -0.0674,  0.0209,  0.0871,  0.0146]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1872, -0.0202,  0.1826], requires_grad=True)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c394106-ad71-4ccb-a3c9-9b60af3fa748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 50])\n",
      "Parameter containing:\n",
      "tensor([[-0.0463,  0.0578, -0.0187,  ...,  0.0253, -0.0897, -0.0720],\n",
      "        [-0.0073, -0.0484, -0.0089,  ..., -0.0108, -0.0800,  0.0053],\n",
      "        [ 0.0588,  0.0185,  0.1333,  ..., -0.1278, -0.0539, -0.0120],\n",
      "        ...,\n",
      "        [-0.0479, -0.1268, -0.0777,  ..., -0.0281, -0.0116,  0.0285],\n",
      "        [-0.0121, -0.0867, -0.0006,  ..., -0.1192, -0.0901, -0.0367],\n",
      "        [ 0.1091,  0.0244, -0.1025,  ...,  0.0948,  0.0506, -0.0906]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weight.shape)\n",
    "print(model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fbcec6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1250,  0.0513,  0.0366,  0.0075,  0.0509,  0.0545, -0.0393,  0.0924,\n",
       "        -0.1412, -0.1232, -0.1063,  0.0081, -0.1249,  0.0101, -0.0019, -0.1298,\n",
       "         0.1388, -0.0330,  0.1017,  0.1247, -0.0554, -0.0417,  0.1388,  0.0159,\n",
       "         0.1215,  0.0385,  0.0769, -0.1224, -0.0279,  0.0991],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.layers[0].bias.shape)\n",
    "model.layers[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b201882b-9285-4db9-bb63-43afe6a2ff9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
      "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
      "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
      "        ...,\n",
      "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
      "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
      "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = NeuralNetwork(50, 3)\n",
    "print(model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1da9a35e-44f3-460c-90fe-304519736fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 50])\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57eadbae-90fe-43a3-a33f-c23a095ba42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1262,  0.1080, -0.1792]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "X = torch.rand((1, 50))\n",
    "out = model(X)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48d720cb-ef73-4b7b-92e0-8198a072defd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1262,  0.1080, -0.1792]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(X)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10df3640-83c3-4061-a74d-08f07a5cc6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3113, 0.3934, 0.2952]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = torch.softmax(model(X), dim=1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19858180-0f26-43a8-b2c3-7ed40abf9f85",
   "metadata": {},
   "source": [
    "## A.6 Setting up efficient data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98d8fc-5618-47a2-bc72-153818972a24",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/10.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9dc2745-8be8-4344-80ef-325f02cda7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor([\n",
    "    [-1.2, 3.1],\n",
    "    [-0.9, 2.9],\n",
    "    [-0.5, 2.6],\n",
    "    [2.3, -1.1],\n",
    "    [2.7, -1.5]\n",
    "])\n",
    "\n",
    "y_train = torch.tensor([0, 0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfb3dd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88283948-5fca-461a-98a1-788b6be191d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor([\n",
    "    [-0.8, 2.8],\n",
    "    [2.6, -1.6],\n",
    "])\n",
    "\n",
    "y_test = torch.tensor([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "edf323e2-1789-41a0-8e44-f3cab16e5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.features = X\n",
    "        self.labels = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        one_x = self.features[index]\n",
    "        one_y = self.labels[index]        \n",
    "        return one_x, one_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "train_ds = ToyDataset(X_train, y_train)\n",
    "test_ds = ToyDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7014705-1fdc-4f72-b892-d8db8bebc331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ec6627a-4c3f-481a-b794-d2131be95eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c9446de-5e4b-44fa-bf9a-a63e2661027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = ToyDataset(X_test, y_test)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9003e956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2000,  3.1000],\n",
       "        [-0.9000,  2.9000],\n",
       "        [-0.5000,  2.6000],\n",
       "        [ 2.3000, -1.1000],\n",
       "        [ 2.7000, -1.5000]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99d4404c-9884-419f-979c-f659742d86ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "Batch 2: tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
      "Batch 3: tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\", x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d003f7e-7a80-40bf-a7fb-7a0d7dbba9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4db4d7f4-82da-44a4-b94e-ee04665d9c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[ 2.3000, -1.1000],\n",
      "        [ 2.7000, -1.5000]]) tensor([1, 1])\n",
      "Batch 2: tensor([[-1.2000,  3.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\", x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb03ed57-df38-4ee0-a553-0863450df39b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/11.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904ca82-e50f-4f3d-a3ac-fc6ca53dd00e",
   "metadata": {},
   "source": [
    "## A.7 A typical training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93f1791a-d887-4fc5-a307-5e5bde9e06f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "515f51b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/003 | Batch 000/002 | Train/Val Loss: 0.75\n",
      "Epoch: 001/003 | Batch 001/002 | Train/Val Loss: 0.65\n",
      "Epoch: 002/003 | Batch 000/002 | Train/Val Loss: 0.44\n",
      "Epoch: 002/003 | Batch 001/002 | Train/Val Loss: 0.13\n",
      "Epoch: 003/003 | Batch 000/002 | Train/Val Loss: 0.03\n",
      "Epoch: 003/003 | Batch 001/002 | Train/Val Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "\n",
    "        logits = model(features)\n",
    "        \n",
    "        loss = F.cross_entropy(logits, labels) # Loss function\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        ### LOGGING\n",
    "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
    "              f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
    "              f\" | Train/Val Loss: {loss:.2f}\")\n",
    "\n",
    "    model.eval()\n",
    "    # Optional model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00dcf57f-6a7e-4af7-aa5a-df2cb0866fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.8569, -4.1618],\n",
      "        [ 2.5382, -3.7548],\n",
      "        [ 2.0944, -3.1820],\n",
      "        [-1.4814,  1.4816],\n",
      "        [-1.7176,  1.7342]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_train)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19be7390-18b8-43f9-9841-d7fb1919f6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.9991,     0.0009],\n",
      "        [    0.9982,     0.0018],\n",
      "        [    0.9949,     0.0051],\n",
      "        [    0.0491,     0.9509],\n",
      "        [    0.0307,     0.9693]])\n",
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "probas = torch.softmax(outputs, dim=1)\n",
    "print(probas)\n",
    "\n",
    "predictions = torch.argmax(probas, dim=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "07e7e530-f8d3-429c-9f5e-cf8078078c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "predictions = torch.argmax(outputs, dim=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f756f0d-63c8-41b5-a5d8-01baa847e026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "da274bb0-f11c-4c81-a880-7a031fbf2943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(predictions == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16d62314-8dee-45b0-8f55-9e5aae2b24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "\n",
    "    model = model.eval()\n",
    "    correct = 0.0\n",
    "    total_examples = 0\n",
    "    \n",
    "    for idx, (features, labels) in enumerate(dataloader):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(features)\n",
    "        \n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        compare = labels == predictions\n",
    "        correct += torch.sum(compare)\n",
    "        total_examples += len(compare)\n",
    "\n",
    "    return (correct / total_examples).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f6c9c17-2a5f-46c0-804b-873f169b729a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "311ed864-e21e-4aac-97c7-c6086caef27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5cd469-3a45-4394-944b-3ce543f41dac",
   "metadata": {},
   "source": [
    "## A.8 Saving and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b013127d-a2c3-4b04-9fb3-a6a7c88d83c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b2b428c2-3a44-4d91-97c4-8298cf2b51eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(2, 2) # needs to match the original model exactly\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f891c013-43da-4a05-973d-997be313d2d8",
   "metadata": {},
   "source": [
    "## A.9 Optimizing training performance with GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ae888-cabf-49c9-bad6-ecdce774db57",
   "metadata": {},
   "source": [
    "### A.9.1 PyTorch computations on GPU devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c845f-efe3-4614-b376-b8b7a9a2c887",
   "metadata": {},
   "source": [
    "See [code-part2.ipynb](code-part2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99811829-b817-42ea-b03e-d35374debcc0",
   "metadata": {},
   "source": [
    "### A.9.2 Single-GPU training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21456c-4af7-440f-9e78-37770277b5bc",
   "metadata": {},
   "source": [
    "See [code-part2.ipynb](code-part2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6eb2d1-a341-4489-b04b-635c26945333",
   "metadata": {},
   "source": [
    "### A.9.3 Training with multiple GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d049a81-5fb0-49b5-9d6a-17a9976d8520",
   "metadata": {},
   "source": [
    "See [DDP-script.py](DDP-script.py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
